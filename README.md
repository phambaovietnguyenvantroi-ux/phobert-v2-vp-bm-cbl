# ğŸš€ PhoBERT Toxic Comment Classifier
### *MÃ´ hÃ¬nh phÃ¢n loáº¡i bÃ¬nh luáº­n Ä‘á»™c háº¡i tiáº¿ng Viá»‡t hiá»‡u quáº£*

<div align="center">

<!-- Animated Title Banner -->
<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=35&duration=4000&pause=1000&color=DC143C&center=true&vCenter=true&width=800&height=100&lines=ğŸ¤–+PhoBERT+Toxic+Classifier;ğŸ‡»ğŸ‡³+Vietnamese+Toxic+Detection;ğŸ¯+Binary+Classification;âš¡+Powered+by+AI+%26+Focal+Loss" alt="Typing SVG" />

<!-- Dynamic Badges -->
![PhoBERT](https://img.shields.io/badge/Model-PhoBERTv2-blue?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=FF6B6B&color=4ECDC4)
![Vietnamese](https://img.shields.io/badge/Language-Vietnamese-red?style=for-the-badge&logo=google-translate&logoColor=white&labelColor=45B7D1&color=96CEB4)
![AI](https://img.shields.io/badge/AI-NLP-green?style=for-the-badge&logo=tensorflow&logoColor=white&labelColor=FFA07A&color=98D8C8)
![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&logoColor=white&labelColor=F7DC6F&color=BB8FCE)

<!-- Glowing Links -->
[![ğŸ¤— Hugging Face Model](https://img.shields.io/badge/ğŸ¤—%20Model-vijjj1/toxic--comment--phobert-ff6b35?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=FF6B35&color=F7931E)](https://huggingface.co/vijjj1/toxic-comment-phobert)
[![ğŸ“Š Dataset](https://img.shields.io/badge/ğŸ“Š%20Dataset-Vietnamese%20Toxic%20Comments-purple?style=for-the-badge&logo=database&logoColor=white&labelColor=9B59B6&color=8E44AD)](https://github.com/your_username/your_repo/blob/main/comments_labels_binary.csv) <!-- Cáº­p nháº­t link dataset náº¿u cÃ³ -->
[![ğŸ® Demo](https://img.shields.io/badge/ğŸ®%20Demo-Gradio%20App-orange?style=for-the-badge&logo=streamlit&logoColor=white&labelColor=E67E22&color=D35400)](https://huggingface.co/spaces/vijjj1/toxic-comment-phobert-demo) <!-- Táº¡o link Gradio náº¿u cÃ³ -->

<!-- GitHub Stats -->
![GitHub stars](https://img.shields.io/github/stars/vijjj1/toxic-comment-phobert?style=for-the-badge&logo=star&logoColor=white&labelColor=FFD700&color=FFA500)
![GitHub forks](https://img.shields.io/github/forks/vijjj1/toxic-comment-phobert?style=for-the-badge&logo=git&logoColor=white&labelColor=32CD32&color=228B22)
![GitHub issues](https://img.shields.io/github/issues/vijjj1/toxic-comment-phobert?style=for-the-badge&logo=github&logoColor=white&labelColor=FF6347&color=DC143C)

<!-- Animated Wave -->
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=0,2,2,5,30&height=150&section=header&text=ğŸ‡»ğŸ‡³%20Vietnamese%20AI%20ğŸ¤–&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%">

</div>

---

## ğŸ¯ **Tá»•ng quan dá»± Ã¡n**

> ğŸ’¡ **Sá»© má»‡nh**: XÃ¢y dá»±ng cÃ´ng cá»¥ AI hiá»‡n Ä‘áº¡i Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i bÃ¬nh luáº­n Ä‘á»™c háº¡i trong tiáº¿ng Viá»‡t trÃªn máº¡ng xÃ£ há»™i, sá»­ dá»¥ng mÃ´ hÃ¬nh PhoBERT v2 vÃ  Focal Loss Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t.

<div align="center">

<!-- Animated Stats Table -->
<table>
<tr>
<td width="50%" align="center">

### ğŸ­ **Kháº£ nÄƒng phÃ¢n loáº¡i**
```mermaid
pie title Toxic Classification
    "ğŸŸ¢ Non-Toxic" : 50
    "ğŸ”´ Toxic" : 50
</td>
<td width="50%" align="center">
ğŸ“± Nguá»“n dá»¯ liá»‡u
code
Mermaid
flowchart TD
    A[ğŸŒ Social Media] --> F[ğŸ¤– PhoBERT Model]
    A --> B[ğŸµ TikTok]
    A --> C[ğŸ“˜ Facebook]
    A --> D[ğŸ¬ YouTube]
    A --> E[ğŸ’¬ Other Platforms]
    B --> G[ğŸ” Preprocessing]
    C --> G
    D --> G
    E --> G
    G --> F
</td>
</tr>
</table>
</div>
<!-- Gradient Line -->
<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" width="100%">
ğŸ“Š ThÃ´ng tin Dataset
<div align="center">
<!-- Animated Counter -->
<img src="https://readme-typing-svg.herokuapp.com?font=Roboto&size=25&duration=2000&pause=500&color=36BCF7&center=true&vCenter=true&width=600&height=60&lines=ğŸ“+Tá»•ng+sá»‘+comments%3A+~11K;ğŸ·ï¸+2+Classes%3A+Toxic%2C+Non-Toxic;ğŸŒ+Multi-Platform+Data;ğŸ¯+CÃ¢n+báº±ng+dá»¯+liá»‡u+vá»›i+Oversampling" alt="Stats Typing" />
ğŸ“ˆ Metric	ğŸ“‹ Value	ğŸ¯ Description
ğŸ“ Comments	
![alt text](https://img.shields.io/badge/~11K-comments-blue?style=flat-square&logo=comment&logoColor=white)
Tá»•ng sá»‘ bÃ¬nh luáº­n Ä‘Æ°á»£c thu tháº­p vÃ  tÄƒng cÆ°á»ng
ğŸ·ï¸ Labels	
![alt text](https://img.shields.io/badge/2-classes-green?style=flat-square&logo=tag&logoColor=white)
non-toxic (0), toxic (1)
ğŸŒ Sources	
![alt text](https://img.shields.io/badge/Multi-platform-orange?style=flat-square&logo=globe&logoColor=white)
Tá»•ng há»£p tá»« nhiá»u nguá»“n máº¡ng xÃ£ há»™i
ğŸ“Š Fields	
![alt text](https://img.shields.io/badge/2-columns-purple?style=flat-square&logo=table&logoColor=white)
comment, label
</div>
<details>
<summary>ğŸ” <strong>Chi tiáº¿t phÃ¢n bá»‘ dá»¯ liá»‡u sau Oversampling</strong></summary>
code
Ascii
ğŸ“Š Label Distribution (Resampled):
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                 â”‚
â”‚  ğŸŸ¢ Non-Toxic: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (50%) â”‚
â”‚  ğŸ”´ Toxic:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (50%) â”‚
â”‚                                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
</details>
âš¡ CÃ i Ä‘áº·t nhanh
<div align="center">
<!-- Installation Animation -->
<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=20&duration=3000&pause=1000&color=FF6B6B&center=true&vCenter=true&width=500&height=50&lines=pip+install+transformers;pip+install+datasets;pip+install+torch;Ready+to+use!+ğŸš€" alt="Installation" />
</div>
ğŸ› ï¸ Requirements
code
Bash
# ğŸ“¦ CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install transformers datasets scikit-learn sentencepiece torch pandas numpy matplotlib seaborn imblearn tqdm huggingface_hub

# ğŸ¨ Hoáº·c cÃ i Ä‘áº·t tá»« requirements.txt
# pip install -r requirements.txt
<details>
<summary>ğŸ’» <strong>Chi tiáº¿t dependencies</strong></summary>
code
Txt
transformers>=4.21.0     # ğŸ¤— Hugging Face Transformers
datasets>=2.4.0          # ğŸ“Š Dataset processing
scikit-learn>=1.1.0      # ğŸ”¬ Machine Learning utilities
sentencepiece>=0.1.97    # ğŸ“ Text tokenization
torch>=1.12.0            # ğŸ”¥ PyTorch framework
gradio>=3.0.0            # ğŸ® Demo interface (náº¿u cÃ³)
numpy>=1.21.0            # ğŸ”¢ Numerical computing
pandas>=1.3.0            # ğŸ“ˆ Data manipulation
matplotlib>=3.5.0        # ğŸ“Š Data visualization
seaborn>=0.11.0          # ğŸ¨ Statistical visualization
imblearn>=0.10.0         # âš–ï¸ Imbalanced-learn (oversampling)
tqdm>=4.0.0              # â³ Progress bars
huggingface_hub>=0.10.0  # ğŸ¤ Hugging Face Hub interaction
</details>
ğŸ—ï¸ HÆ°á»›ng dáº«n Training
ğŸš€ Quick Start
code
Python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# ğŸ”§ Khá»Ÿi táº¡o model vÃ  tokenizer
print("ğŸ¤– Loading PhoBERT model...")
model_name = "vinai/phobert-base-v2" # Hoáº·c "vinai/phobert-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2,
    id2label={0: "NON-TOXIC", 1: "TOXIC"},
    label2id={"NON-TOXIC": 0, "TOXIC": 1}
)

print("âœ… Model loaded successfully!")
print(f"ğŸ¯ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}")

# Chuyá»ƒn model vá» cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡ náº¿u chá»‰ Ä‘á»ƒ dá»± Ä‘oÃ¡n
model.eval()
ğŸ“‹ Training Process
<div align="center">
code
Mermaid
graph TD
    A[ğŸ“Š Load CSV (comments_labels_binary.csv)] --> A1(ğŸ” Xá»­ lÃ½ trÃ¹ng láº·p & thá»‘ng kÃª)
    A1 --> A2(ğŸ“‰ PhÃ¢n bá»‘ nhÃ£n trÆ°á»›c oversampling)
    A2 --> B[ğŸ”§ TÄƒng cÆ°á»ng dá»¯ liá»‡u Toxic (Data Augmentation)]
    B --> C[âš–ï¸ Oversampling vá»›i RandomOverSampler]
    C --> C1(ğŸ“ˆ PhÃ¢n bá»‘ nhÃ£n sau oversampling)
    C1 --> D[âœ‚ï¸ Chia Train/Test (70%/30%)]
    D --> E[ğŸ“ Tokenization vá»›i PhoBERT]
    E --> F[ğŸ‹ï¸ Training Loop (Focal Loss)]
    F --> G[ğŸ“ˆ Validation & Early Stopping]
    G --> H[ğŸ’¾ Save Best Model]
    H --> I[ğŸš€ Push to Hugging Face Hub]

    style A fill:#FF6B6B,stroke:#333,stroke-width:2px,color:#fff
    style A1 fill:#FDDA0D,stroke:#333,stroke-width:2px,color:#333
    style A2 fill:#FDDA0D,stroke:#333,stroke-width:2px,color:#333
    style B fill:#4ECDC4,stroke:#333,stroke-width:2px,color:#fff
    style C fill:#45B7D1,stroke:#333,stroke-width:2px,color:#fff
    style C1 fill:#FDDA0D,stroke:#333,stroke-width:2px,color:#333
    style D fill:#96CEB4,stroke:#333,stroke-width:2px,color:#fff
    style E fill:#FECA57,stroke:#333,stroke-width:2px,color:#fff
    style F fill:#FF9FF3,stroke:#333,stroke-width:2px,color:#fff
    style G fill:#54A0FF,stroke:#333,stroke-width:2px,color:#fff
    style H fill:#5F27CD,stroke:#333,stroke-width:2px,color:#fff
    style I fill:#00ADB5,stroke:#333,stroke-width:2px,color:#fff
</div>
<table>
<tr>
<td width="50%">
ğŸ¯ BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u
code
Python
import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

df = pd.read_csv("comments_labels_binary.csv", encoding='utf-8-sig')
df = df.drop_duplicates(subset=['comment']) # Loáº¡i bá» trÃ¹ng láº·p
df['label'] = pd.to_numeric(df['label'], errors='coerce').dropna().astype(int)

# TÄƒng cÆ°á»ng vÃ  Oversampling
# (Xem chi tiáº¿t trong code training Ä‘á»ƒ hiá»ƒu cÃ¡ch thá»±c hiá»‡n)

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(df[['comment']], df['label'])
df_resampled = pd.DataFrame({'comment': X_resampled['comment'], 'label': y_resampled})

train_df, test_df = train_test_split(df_resampled, test_size=0.3, random_state=42, stratify=df_resampled['label'])

print(f"ğŸ“ˆ Training samples: {len(train_df)}")
print(f"ğŸ§ª Test samples: {len(test_df)}")
</td>
<td width="50%">
ğŸƒâ€â™‚ï¸ BÆ°á»›c 2: Huáº¥n luyá»‡n
code
Python
# Khá»Ÿi táº¡o DataLoader, Model, Optimizer, Scheduler
# (ÄÃ£ Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong file training.py)

# Lá»›p Focal Loss
class FocalLoss(torch.nn.Module):
    def __init__(self, alpha=0.75, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
    def forward(self, logits, targets):
        ce_loss = F.cross_entropy(logits, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()
        return focal_loss

# Sá»­ dá»¥ng Focal Loss
loss_fn = FocalLoss(alpha=0.75, gamma=2.0)

# Báº¯t Ä‘áº§u vÃ²ng láº·p huáº¥n luyá»‡n
# (Xem chi tiáº¿t trong file training.py)

# Sau huáº¥n luyá»‡n, lÆ°u vÃ  Ä‘áº©y model lÃªn Hugging Face Hub
# model.push_to_hub("vijjj1/toxic-comment-phobert")
# tokenizer.push_to_hub("vijjj1/toxic-comment-phobert")
print("âœ… HoÃ n táº¥t quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘áº©y lÃªn Hugging Face!")
</td>
</tr>
</table>
ğŸ“ˆ Káº¿t quáº£ Performance
<div align="center">
ğŸ† Model Performance
<!-- Animated Performance Metrics -->
<img src="https://readme-typing-svg.herokuapp.com?font=Roboto+Mono&size=22&duration=2500&pause=800&color=36BCF7&center=true&vCenter=true&width=700&lines=ğŸ¯+Accuracy%3A+~93%25;ğŸ“Š+F1-Score%3A+~93%25;âœ…+High+Recall+for+Toxic;ğŸ”+Effective+Toxic+Detection" alt="Performance" />
ğŸ“Š Metric	ğŸ“ˆ Score	ğŸ¯ Details
ğŸ¯ Accuracy	
![alt text](https://img.shields.io/badge/93%25-success-brightgreen?style=for-the-badge&logo=target)
Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ (vÃ­ dá»¥)
ğŸ“Š F1-Score	
![alt text](https://img.shields.io/badge/93%25-good-green?style=for-the-badge&logo=chart-line)
F1-score trung bÃ¬nh (vÃ­ dá»¥)
ğŸŸ¢ Recall (Toxic)	
![alt text](https://img.shields.io/badge/Toxic%20Recall-~95%25-red?style=for-the-badge&logo=shield)
Kháº£ nÄƒng phÃ¡t hiá»‡n Ä‘Ãºng bÃ¬nh luáº­n Ä‘á»™c háº¡i
âšª Precision (Non-Toxic)	
![alt text](https://img.shields.io/badge/Non--Toxic%20Precision-~92%25-blue?style=for-the-badge&logo=thumbs-up)
Äá»™ chÃ­nh xÃ¡c khi phÃ¢n loáº¡i khÃ´ng Ä‘á»™c háº¡i
</div>
ğŸ“Š Detailed Results
Dá»±a trÃªn káº¿t quáº£ classification_report tá»« code cá»§a báº¡n:
code
Ascii
ğŸ­ Classification Performance:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚   Class     â”‚ Precision   â”‚   Recall    â”‚   F1-Score  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ Non-Toxicâ”‚    0.9200   â”‚    0.9100   â”‚    0.9100   â”‚
â”‚ ğŸ”´ Toxic    â”‚    0.9400   â”‚    0.9500   â”‚    0.9400   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Accuracy  â”‚             â”‚             â”‚    0.9300   â”‚
â”‚   Macro Avg â”‚    0.9300   â”‚    0.9300   â”‚    0.9300   â”‚
â”‚ Weighted Avgâ”‚    0.9300   â”‚    0.9300   â”‚    0.9300   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
LÆ°u Ã½: CÃ¡c sá»‘ liá»‡u trÃªn lÃ  vÃ­ dá»¥ dá»±a trÃªn hÃ¬nh áº£nh. Káº¿t quáº£ thá»±c táº¿ cÃ³ thá»ƒ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o quÃ¡ trÃ¬nh training cuá»‘i cÃ¹ng vÃ  ngÆ°á»¡ng phÃ¢n loáº¡i.
<div align="center">
code
Mermaid
xychart-beta
    title "ğŸ“Š Model Performance by Class (F1-Score)"
    x-axis [Non-Toxic, Toxic]
    y-axis "F1-Score" 0 --> 1
    bar [0.91, 0.94]
</div>
Ma tráº­n nháº§m láº«n:
Vá»›i káº¿t quáº£ confusion_matrix cá»§a báº¡n:
[[2839 285]
[ 172 3192]]
